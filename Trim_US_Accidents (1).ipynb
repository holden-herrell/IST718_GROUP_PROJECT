{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Required Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in US Accident Data and extract concerned cities\n",
    "US_Accidents=\"C:/Users/herre/Downloads/US_Accidents_Dec19.csv\"\n",
    "US = dd.read_csv(US_Accidents)\n",
    "\n",
    "cityList=('Atlanta','Athens', 'Cumberland', 'Statham', 'Duluth', 'Norcross'\n",
    "         , 'Peachtree Corners', 'Monroe', 'Suwanee', 'Johns Creek', 'Winder'\n",
    "        , 'Dallas','Forth Worth', 'Arlington', 'Forest Hill'\n",
    "         , 'Grand Prairie', 'Cedar Hills', 'Duncanville', 'Mansfield'\n",
    "        , 'Houston','Miami','Sunrise', 'Fort Lauderdale', 'Dania Beach', 'Hollywood'\n",
    "        , 'Oakland Park', 'Wilton Manors', 'North Andrews Barden', 'Launderhills'\n",
    "         , 'Lauderdale Lakes', 'Plantation', 'Davie')\n",
    "ATLlist=('Atlanta','Athens', 'Cumberland', 'Statham', 'Duluth', 'Norcross'\n",
    "         , 'Peachtree Corners', 'Monroe', 'Suwanee', 'Johns Creek', 'Winder')\n",
    "DALlist=('Dallas','Forth Worth', 'Arlington', 'Forest Hill'\n",
    "         , 'Grand Prairie', 'Cedar Hills', 'Duncanville', 'Mansfield')\n",
    "HOUlist=('Houston')\n",
    "MIAlist=('Miami','Sunrise', 'Fort Lauderdale', 'Dania Beach', 'Hollywood'\n",
    "        , 'Oakland Park', 'Wilton Manors', 'North Andrews Barden', 'Launderhills', 'Lauderdale Lakes', 'Plantation', 'Davie')\n",
    "USCity=US[US['City'].isin(cityList)]\n",
    "USdf=USCity.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trim data to 2017 and later\n",
    "USdf1=USdf[USdf['Start_Time']>('2016-12-31 23:59:59')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop Unneeded columns\n",
    "USdf1=USdf1.drop(columns=['ID','Description','County','Country','Airport_Code','TMC','Source','Street','Timezone'\n",
    "                          ,'Astronomical_Twilight','Civil_Twilight','Nautical_Twilight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlanta and surrounding 35049\n",
      "Atlanta 31283\n",
      "Dallas and surrounding 54257\n",
      "Dallas 46156\n",
      "Houston 77722\n",
      "Houston 77722\n",
      "Miami and surrounding 37990\n",
      "Miami 26016\n"
     ]
    }
   ],
   "source": [
    "#Check for correct number including adjacent areas\n",
    "print('Atlanta and surrounding', sum(USdf1['City'].isin(ATLlist)))\n",
    "print('Atlanta', sum(USdf1['City']=='Atlanta'))\n",
    "print('Dallas and surrounding',sum(USdf1['City'].isin(DALlist)))\n",
    "print('Dallas', sum(USdf1['City']=='Dallas'))\n",
    "print('Houston', sum(USdf1['City']==(HOUlist)))\n",
    "print('Houston', sum(USdf1['City']=='Houston'))\n",
    "print('Miami and surrounding', sum(USdf1['City'].isin(MIAlist)))\n",
    "print('Miami', sum(USdf1['City']=='Miami'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data by city\n",
    "ATL_Accidents=pd.DataFrame(USdf1[USdf1['City'].isin(ATLlist)])\n",
    "ATL_Accidents=pd.DataFrame(ATL_Accidents[ATL_Accidents['State']=='GA'])\n",
    "ATL_Accidents['City']='Atlanta'\n",
    "DAL_Accidents=pd.DataFrame(USdf1[USdf1['City'].isin(DALlist)])\n",
    "DAL_Accidents=pd.DataFrame(DAL_Accidents[DAL_Accidents['State']=='TX'])\n",
    "DAL_Accidents['City']='Dallas'\n",
    "HOU_Accidents=pd.DataFrame(USdf1[USdf1['City']==(HOUlist)])\n",
    "HOU_Accidents=pd.DataFrame(HOU_Accidents[HOU_Accidents['State']=='TX'])\n",
    "HOU_Accidents['City']='Houston'\n",
    "MIA_Accidents=pd.DataFrame(USdf1[USdf1['City'].isin(MIAlist)])\n",
    "MIA_Accidents=pd.DataFrame(MIA_Accidents[MIA_Accidents['State']=='FL'])\n",
    "MIA_Accidents['City']='Miami'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Atlanta 33624\n",
      "Dallas 50838\n",
      "Houston 77679\n",
      "Miami 37915\n"
     ]
    }
   ],
   "source": [
    "#Check for correct number including adjacent areas\n",
    "print('Atlanta', sum(ATL_Accidents['City']=='Atlanta'))\n",
    "print('Dallas', sum(DAL_Accidents['City']=='Dallas'))\n",
    "print('Houston', sum(HOU_Accidents['City']=='Houston'))\n",
    "print('Miami', sum(MIA_Accidents['City']=='Miami'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATL_Accidents.to_csv('ATL_Accidents.csv', index=False)\n",
    "DAL_Accidents.to_csv('DAL_Accidents.csv', index=False)\n",
    "HOU_Accidents.to_csv('HOU_Accidents.csv', index=False)\n",
    "MIA_Accidents.to_csv('MIA_Accidents.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
